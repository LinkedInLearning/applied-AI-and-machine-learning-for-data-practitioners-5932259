{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7260a3b2",
   "metadata": {},
   "source": [
    "# Python for AI Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecbf1fa",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**Generative AI and Agentic AI**\n",
    "\n",
    "In this Jupyter notebook - we'll quickly setup our Python environment and see how we can run a series of Streamlit dashboards within our Google Colab workspace.\n",
    "\n",
    "**⚠️ BEFORE YOU BEGIN!**\n",
    "\n",
    "Make sure you’re using the **GPU runtime** in Google Colab for better performance when running local language models like TinyLlama.\n",
    "\n",
    "To enable GPU runtime, please go to the menu:  \n",
    "**Runtime → Change runtime type → Hardware accelerator → GPU**\n",
    "\n",
    "### Executing Code Cells\n",
    "\n",
    "To execute each cell in this notebook - you can click on the play button on the left of each cell or hit `command/shift + enter` when you're navigating to the cell.\n",
    "\n",
    "### Setup and Installation\n",
    "\n",
    "In the following cell we'll run a few commands to install the required Python packages and also grab all of our Streamlit application code and data artefacts from our GitHub repository.\n",
    "\n",
    "The cell below should around ~2 minutes to run as we'll need to download and cache a few large-language models from Hugging Face!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47247eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# Initial setup steps\n",
    "# ====================\n",
    "\n",
    "# Install Python libraries\n",
    "!pip install --quiet faiss-cpu==1.11.0\n",
    "!pip install --quiet ctransformers==0.2.27\n",
    "!pip install --quiet dotenv==0.9.9\n",
    "!pip install --quiet pyngrok==7.2.12\n",
    "!pip install --quiet streamlit==1.47.1\n",
    "\n",
    "# Clone GitHub repo into a \"data\" folder\n",
    "!git clone https://github.com/LinkedInLearning/applied-AI-and-machine-learning-for-data-practitioners-5932259.git data\n",
    "\n",
    "# Need to change directory into \"data\" to download git lfs data objects\n",
    "%cd data\n",
    "!git lfs pull\n",
    "\n",
    "# Then we need to change directory back up so all our paths are correct\n",
    "%cd ..\n",
    "\n",
    "# Turn off future warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Frontload the necessary LLM and AI libraries we'll be using in this tutorial\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from huggingface_hub import hf_hub_download, snapshot_download\n",
    "import os\n",
    "\n",
    "cache_root = \"data/models\"\n",
    "\n",
    "# this cache_dir is important as we'll reuse this in some of our Streamlit apps\n",
    "tiny_llama_model_path = hf_hub_download(\n",
    "    repo_id=\"TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF\",\n",
    "    filename=\"tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf\",\n",
    "    cache_dir=cache_root\n",
    ")\n",
    "\n",
    "# Download and cache our embedding model\n",
    "embedding_model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "cached_embedding_model_path = snapshot_download(\n",
    "  repo_id=embedding_model_id,\n",
    "  cache_dir=cache_root\n",
    ")\n",
    "\n",
    "# We'll use this path to refer to our cached embedding model in our Streamlit apps\n",
    "print(cached_embedding_model_path)\n",
    "print(\"✅ Initial setup steps complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6e3f9a",
   "metadata": {},
   "source": [
    "# 1. Introduction to Streamlit\n",
    "\n",
    "Welcome to this hands-on tutorial! In this notebook, we’ll be using Streamlit, a lightweight Python framework for building interactive web dashboards and AI apps — all with minimal code.\n",
    "\n",
    "## 1.1 What is Streamlit?\n",
    "\n",
    "Streamlit lets you turn any Python script into a shareable web app using simple commands like st.write(), st.text_input(), and st.button().\n",
    "\n",
    "It's perfect for:\n",
    "\n",
    "- Visualizing data and model predictions\n",
    "- Prototyping dashboards\n",
    "- Building AI-powered tools quickly\n",
    "\n",
    "## 1.2 The Challenge in Google Colab\n",
    "\n",
    "Because Colab runs on remote virtual machines, we can’t directly access localhost ports like we would on our own computers.\n",
    "\n",
    "That means even if we run:\n",
    "\n",
    "```python\n",
    "streamlit run app.py\n",
    "```\n",
    "\n",
    "We still won't be able to visit localhost:8501 in our browser to view our application!\n",
    "\n",
    "## 1.3 Ngrok for Secure Tunnels\n",
    "\n",
    "To solve this, we’ll use Ngrok, a tool that creates a secure tunnel from the internet to your Colab machine.\n",
    "\n",
    "We’ll use the following pattern for all of our Streamlit apps in this tutorial:\n",
    "\n",
    "- Start running our Streamlit apps on port `8051` (we’ll avoid `8501` to reduce potential conflicts)\n",
    "- Use Ngrok to expose port 8051 to a public web URL\n",
    "- Visit the generated public URL to view our live dashboards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff40b3",
   "metadata": {},
   "source": [
    "# 2. Pre-flight Checks\n",
    "\n",
    "We will need to setup a few secure access components before we can proceed with our Streamlit and AI agents tutorial.\n",
    "\n",
    "## 2.1 Setup Ngrok Account\n",
    "\n",
    "1. Create Ngrok account at https://dashboard.ngrok.com/signup\n",
    "2. Acquire your `AuthToken` at https://dashboard.ngrok.com/get-started/your-authtoken\n",
    "\n",
    "![ngrok-copy-auth-token](https://raw.githubusercontent.com/LinkedInLearning/applied-AI-and-machine-learning-for-data-practitioners-5932259/main/images/ngrok-copy-auth-token.png)\n",
    "\n",
    "## 2.2 Setup OpenRouter Account\n",
    "\n",
    "1. Create OpenRouter account at https://openrouter.ai/sign-up\n",
    "2. Create an API token at https://openrouter.ai/settings/keys with **read only** access and spend limit set to $0\n",
    "\n",
    "![open-router-create-api-key](https://raw.githubusercontent.com/LinkedInLearning/applied-AI-and-machine-learning-for-data-practitioners-5932259/main/images/open-router-create-api-key.png)\n",
    "\n",
    "3. Store this API key safely as you won't be able to see it again once you click away\n",
    "\n",
    "> **WARNING 🚨🚨🚨** don't be like me and share your key publicly like in this image! This example is just for illustration and I've already deleted this set of API keys on my account!!!!!!! 🥵\n",
    "\n",
    "![open-router-copy-api-key](https://raw.githubusercontent.com/LinkedInLearning/applied-AI-and-machine-learning-for-data-practitioners-5932259/main/images/open-router-copy-api-key.png)\n",
    "\n",
    "## 2.3 Streamlit Password\n",
    "\n",
    "We'll also secure our Streamlit apps by using a simple authentication password. This ensures that our publicly available URL still has a layer of authentication in-memory so only we can access it.\n",
    "\n",
    "Simply decide on a simple password for your Streamlit applications - but note that you'll need to type this when we start viewing our dashboards, so I wouldn't make it too long or complicated for a better learning experience!\n",
    "\n",
    "## 2.4 Setup Authentication\n",
    "\n",
    "Run the code cell immediately below to populate a local `.env` file with your sensitive information we setup in the previous step!\n",
    "\n",
    "Make sure you have the following ready so you can paste it in when prompted in the following cell:\n",
    "\n",
    "* Ngrok Auth Token\n",
    "* OpenRouter API Key\n",
    "* Streamlit password (remember to keep it short as we'll need to type it for every Streamlit app we run!)\n",
    "\n",
    "We’ll ask for these values securely using getpass, and store them in a local `.env` file so they’re not exposed in the notebook.\n",
    "\n",
    "> **Warning 🚨🚨🚨** Make sure to never share your Auth and API keys and be careful to avoid exposing them to the public especially when commiting files into GitHub! I've also setup a secure cleaup step to make sure we remove the `.env` file at [bottom of this notebook!](#final-steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb81637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Secure .env Setup Script\n",
    "# =========================\n",
    "import getpass\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "# Step 1: Check if .env file exists\n",
    "if os.path.exists(\".env\"):\n",
    "    print(\"✅ .env file already exists!\")\n",
    "\n",
    "    # Load existing environment variables\n",
    "    dotenv.load_dotenv()\n",
    "\n",
    "    # Check each required variable individually\n",
    "    ngrok_token = os.getenv(\"NGROK_AUTH_TOKEN\")\n",
    "    if not ngrok_token:\n",
    "        ngrok_token = getpass.getpass(\"🔐 Paste your NGROK_AUTH_TOKEN: \")\n",
    "        with open(\".env\", \"a\") as f:\n",
    "            f.write(f'NGROK_AUTH_TOKEN={ngrok_token}\\n')\n",
    "\n",
    "    openrouter_key = os.getenv(\"OPEN_ROUTER_API_KEY\")\n",
    "    if not openrouter_key:\n",
    "        openrouter_key = getpass.getpass(\"🔐 Paste your OPEN_ROUTER_API_KEY: \")\n",
    "        with open(\".env\", \"a\") as f:\n",
    "            f.write(f'OPEN_ROUTER_API_KEY={openrouter_key}\\n')\n",
    "\n",
    "    streamlit_password = os.getenv(\"STREAMLIT_PASSWORD\")\n",
    "    if not streamlit_password:\n",
    "        password_input = getpass.getpass(\"🔐 Set your STREAMLIT_PASSWORD (press Enter to use default): \")\n",
    "        streamlit_password = password_input or \"linkedin-learning\"\n",
    "        if password_input == \"\":\n",
    "            print(f\"ℹ️ No password entered — using default: {streamlit_password}\")\n",
    "        else:\n",
    "            print(\"✅ Streamlit password set!\")\n",
    "        with open(\".env\", \"a\") as f:\n",
    "            f.write(f'STREAMLIT_PASSWORD={streamlit_password}\\n')\n",
    "\n",
    "    print(\"✅ All required environment variables are now set!\")\n",
    "\n",
    "# Step 2: If .env does not exist, prompt for everything\n",
    "else:\n",
    "    print(\"⚙️ .env file not found — let's create one now!\")\n",
    "\n",
    "    ngrok_token = getpass.getpass(\"🔐 Paste your NGROK_AUTH_TOKEN: \")\n",
    "    openrouter_key = getpass.getpass(\"🔐 Paste your OPEN_ROUTER_API_KEY: \")\n",
    "    password_input = getpass.getpass(\"🔐 Set your STREAMLIT_PASSWORD (press Enter to use default): \")\n",
    "\n",
    "    streamlit_password = password_input or \"linkedin-learning\"\n",
    "    if password_input == \"\":\n",
    "        print(f\"ℹ️ No password entered — using default: {streamlit_password}\")\n",
    "    else:\n",
    "        print(\"✅ Streamlit password set! (hidden)\")\n",
    "\n",
    "    with open(\".env\", \"w\") as f:\n",
    "        f.write(f'NGROK_AUTH_TOKEN={ngrok_token}\\n')\n",
    "        f.write(f'OPEN_ROUTER_API_KEY={openrouter_key}\\n')\n",
    "        f.write(f'STREAMLIT_PASSWORD={streamlit_password}\\n')\n",
    "\n",
    "    print(\"✅ .env file created securely!\")\n",
    "\n",
    "# Step 3: Append model paths to .env\n",
    "with open(\".env\", \"a\") as f:\n",
    "    f.write(f'TINY_LLAMA_MODEL_PATH={tiny_llama_model_path}\\n')\n",
    "    f.write(f'EMBEDDING_MODEL_PATH={cached_embedding_model_path}\\n')\n",
    "print(\"✅ Local model paths appended to .env file!\")\n",
    "\n",
    "# Finally - load in the newly created environment variables\n",
    "dotenv.load_dotenv()\n",
    "print(\"✅ Latest .env file successfully loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b19c6d8",
   "metadata": {},
   "source": [
    "# 3. Streamlit Hello World App\n",
    "\n",
    "In the next section, we’ll demonstrate how to run a basic Streamlit app to help verify everything is working smoothly before we dive deeper into our GenAI Streamlit applications.\n",
    "\n",
    "## 3.1 Streamlit Helper Functions\n",
    "\n",
    "We'll firstly define some Python helper functions to help us launch and shutdown our Streamlit applications using Ngrok to host our live dashboards.\n",
    "\n",
    "We'll also include one function to allow us to inspect the source code for our Streamlit application code.\n",
    "\n",
    "You can run the cell directly below to initialize these functions:\n",
    "\n",
    "* `launch_streamlit_in_colab`\n",
    "* `shutdown_streamlit_and_ngrok`\n",
    "* `render_python_file_as_markdown`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca350709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_streamlit_in_colab(app_path: str):\n",
    "    \"\"\"\n",
    "    Launch a Streamlit app within Google Colab using an ngrok tunnel.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    app_path : str\n",
    "        Path to the Streamlit `.py` app file to be launched (e.g., \"app.py\")\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    public_url : str\n",
    "        A publicly accessible ngrok URL that points to the Streamlit app running on port 8501.\n",
    "\n",
    "    This function performs:\n",
    "    ------------------------\n",
    "    - Authenticates with ngrok using a token stored in the .env file (`NGROK_AUTH_TOKEN`)\n",
    "    - Kills any existing ngrok tunnels\n",
    "    - Launches a new tunnel to port 8501\n",
    "    - Starts the Streamlit app in the background\n",
    "    - Waits briefly to allow the app to start up\n",
    "    \"\"\"\n",
    "\n",
    "    import os\n",
    "    import time\n",
    "    from pyngrok import ngrok\n",
    "\n",
    "    # ----------------------------\n",
    "    # Set ngrok authentication token\n",
    "    # ----------------------------\n",
    "    ngrok.set_auth_token(os.getenv(\"NGROK_AUTH_TOKEN\"))\n",
    "\n",
    "    # ----------------------------\n",
    "    # Kill any existing tunnels\n",
    "    # ----------------------------\n",
    "    ngrok.kill()\n",
    "\n",
    "    # ----------------------------\n",
    "    # Open a new tunnel to port 8501\n",
    "    # ----------------------------\n",
    "    public_url = ngrok.connect(8501, \"http\")\n",
    "    print(f\"✅ Streamlit app will be live at: {public_url}\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # Start the Streamlit app in the background\n",
    "    # ----------------------------\n",
    "    os.system(f\"streamlit run {app_path} &>/content/logs.txt &\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # Wait a few seconds to ensure the app starts\n",
    "    # ----------------------------\n",
    "    time.sleep(3)\n",
    "\n",
    "    return public_url\n",
    "\n",
    "def shutdown_streamlit_and_ngrok():\n",
    "    \"\"\"\n",
    "    Shut down any running Streamlit app and terminate all ngrok tunnels in a Colab session.\n",
    "\n",
    "    This function performs:\n",
    "    ------------------------\n",
    "    - Kills all active ngrok tunnels using the pyngrok API\n",
    "    - Terminates any background Streamlit processes using `pkill`\n",
    "    - Provides feedback via console print statements\n",
    "    \"\"\"\n",
    "\n",
    "    import os\n",
    "    from pyngrok import ngrok\n",
    "\n",
    "    print(\"⛔ Shutting down Streamlit and ngrok...\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # Kill all active ngrok tunnels\n",
    "    # ----------------------------\n",
    "    try:\n",
    "        ngrok.kill()\n",
    "        print(\"✅ ngrok tunnel(s) killed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error killing ngrok: {e}\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # Kill all background Streamlit processes\n",
    "    # ----------------------------\n",
    "    os.system(\"pkill -f streamlit\")\n",
    "    print(\"✅ Streamlit processes killed.\")\n",
    "    \n",
    "def render_python_file_as_markdown(path: str):\n",
    "    \"\"\"\n",
    "    Render the contents of a Python script as syntax-highlighted Markdown in a Colab or Jupyter notebook.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    path : str\n",
    "        File path to the Python script to be rendered (e.g., \"app.py\")\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    IPython.display.Markdown\n",
    "        A Markdown object that displays the script with Python syntax highlighting.\n",
    "    \"\"\"\n",
    "\n",
    "    from IPython.display import Markdown\n",
    "\n",
    "    # ----------------------------\n",
    "    # Read file contents\n",
    "    # ----------------------------\n",
    "    with open(path, \"r\") as f:\n",
    "        code = f.read()\n",
    "\n",
    "    # ----------------------------\n",
    "    # Format and return as Markdown code block\n",
    "    # ----------------------------\n",
    "    return Markdown(f\"```python\\n{code}\\n```\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae70fae",
   "metadata": {},
   "source": [
    "## 3.2 Running our Streamlit Application\n",
    "\n",
    "Once we run the `launch_streamlit_in_colab(\"data/streamlit-hello-world.py\")` command in the following cell and you click on the shared URL link - we should see the following screens (if all things go well!)\n",
    "\n",
    "> ✅ Make sure to click on the URL which looks like this: `\"https://<some-random-string>.ngrok-free.app\"` instead of `\"http://localhost:8501\"`\n",
    "\n",
    "After clicking on this URL - you should see this welcome page from Ngrok which might seem alarming but it's fine to click on `Visit Site` to proceed!\n",
    "\n",
    "![streamlit-hello-world-ngrok](https://raw.githubusercontent.com/LinkedInLearning/applied-AI-and-machine-learning-for-data-practitioners-5932259/main/images/streamlit-hello-world-ngrok.png)\n",
    "\n",
    "You should first be welcomed by an authentication page.\n",
    "\n",
    "![streamlit-hello-world-login](https://raw.githubusercontent.com/LinkedInLearning/applied-AI-and-machine-learning-for-data-practitioners-5932259/main/images/streamlit-hello-world-login.png)\n",
    "\n",
    "Then following this - you should see text input asking for a prompt.\n",
    "\n",
    "![streamlit-hello-world-prompt](https://raw.githubusercontent.com/LinkedInLearning/applied-AI-and-machine-learning-for-data-practitioners-5932259/main/images/streamlit-hello-world-prompt.png)\n",
    "\n",
    "Finally - if all goes well, you should see something like this output - try it out using your own prompts!\n",
    "\n",
    "![streamlit-hello-world-success](https://raw.githubusercontent.com/LinkedInLearning/applied-AI-and-machine-learning-for-data-practitioners-5932259/main/images/streamlit-hello-world-success.png)\n",
    "\n",
    "After you're done with this hello world example - you can run the cell directly below to stop running the Streamlit application and continue with our tutorial!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b0498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the Streamlit app in Colab\n",
    "launch_streamlit_in_colab(\"data/streamlit-hello-world.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df70ad04",
   "metadata": {},
   "source": [
    "## 3.3 Shutdown Streamlit and Ngrok\n",
    "\n",
    "Once you're ready to move onto the next component - we can shutdown our Streamlit app and free up the Ngrok tunnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e9f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutdown the Streamlit app in Colab\n",
    "shutdown_streamlit_and_ngrok()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2682ae",
   "metadata": {},
   "source": [
    "## 3.4 View Streamlit App Source Code\n",
    "\n",
    "The source code for the streamlit app is below with lots of code comments to clearly highlight every step of the way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232cb9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_python_file_as_markdown(\"data/streamlit-hello-world.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e2ce2c",
   "metadata": {},
   "source": [
    "# 4. Pure Python LLM App\n",
    "\n",
    "In the next cell - we'll run a Streamlit app which details a simple `Retrieval-Augmented-Generation` (RAG) pipeline using pure Python only.\n",
    "\n",
    "This will help us set the stage before we start applying higher-level abstractions using the `LangChain` and `LangGraph` frameworks to modularize our application.\n",
    "\n",
    "**Placeholder for Exclalidraw diagram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa225bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for pure Python app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a791a1a",
   "metadata": {},
   "source": [
    "# 5. LangChain App\n",
    "\n",
    "In the next cell - we'll run a Streamlit app which extends our pure Python app by replacing certain components using `LangChain`\n",
    "\n",
    "**Placeholder for Exclalidraw diagram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fc9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for LangChain app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e64001e",
   "metadata": {},
   "source": [
    "# 5. LangGraph Agentic AI\n",
    "\n",
    "In the next cell - we'll run a Streamlit app which further extends upon our static AI workflows using `LangChain` to an autonomous agentic AI framework using `LangGraph`\n",
    "\n",
    "**Placeholder for Exclalidraw diagram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a056858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for LangGraph app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d936e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup - kill any ngrok tunnels and delete sensitive .env file\n",
    "import os\n",
    "import dotenv\n",
    "from pyngrok import ngrok\n",
    "\n",
    "if os.path.exists(\".env\"):\n",
    "    \n",
    "    # Load environment variables from .env file\n",
    "    dotenv.load_dotenv()\n",
    "\n",
    "    # Check if NGROK_AUTH_TOKEN is set and stop any existing tunnels\n",
    "    if os.getenv(\"NGROK_AUTH_TOKEN\"):\n",
    "        ngrok.set_auth_token(os.getenv(\"NGROK_AUTH_TOKEN\"))\n",
    "\n",
    "        # Stop any existing Ngrok tunnels\n",
    "        ngrok.kill()\n",
    "        print(\"✅ Ngrok tunnels stopped.\")\n",
    "    \n",
    "    # Remove the .env file\n",
    "    os.remove(\".env\")\n",
    "    print(\"✅ .env file removed safely.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
